{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# owner__title__cpu/memory__extraName__sandbox\n",
    "\n",
    "# e.g. janitha__CPU_Usage__cpu__centralized_plugin__m1\n",
    "# e.g. janitha__CPU_Usage__cpu__centralized_plugin__m2\n",
    "# e.g. janitha__CPU_Usage__cpu__centralized_plugin__m3\n",
    "# e.g. janitha__Memory_Usage__memory__centralized_plugin__m1\n",
    "# e.g. janitha__Memory_Usage__memory__centralized_plugin__m2\n",
    "# e.g. janitha__Memory_Usage__memory__centralized_plugin__m3\n",
    "# e.g. janitha__CPU_Usage__cpu__distributed_plugin__m1\n",
    "# e.g. janitha__CPU_Usage__cpu__distributed_plugin__m2\n",
    "# e.g. janitha__CPU_Usage__cpu__distributed_plugin__m3\n",
    "# e.g. janitha__Memory_Usage__memory__distributed_plugin__m1\n",
    "# e.g. janitha__Memory_Usage__memory__distributed_plugin__m2\n",
    "# e.g. janitha__Memory_Usage__memory__distributed_plugin__m3\n",
    "\n",
    "name_mapper = {\n",
    "    \"x_label\" : \"Time\",\n",
    "    \"cpu\" : \"CPU (%)\",\n",
    "    \"memory\": \"Memory (MB)\",\n",
    "    \"m1\" : \"Machine 1\",\n",
    "    \"m2\" : \"Machine 2\",\n",
    "    \"m3\" : \"Machine 3\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mib(memory):\n",
    "    # Convert memory to MiB if necessary\n",
    "    if 'GiB' in memory:\n",
    "        memory_in_gib = float(memory[:-3])\n",
    "        memory_in_mib = memory_in_gib * 1024\n",
    "        return f\"{memory_in_mib:.2f}MiB\"\n",
    "    elif 'MiB' in memory:\n",
    "        return memory\n",
    "    else:\n",
    "        raise ValueError(\"Invalid memory format\")\n",
    "\n",
    "\n",
    "def extract_info(file_name):\n",
    "    cpu_percentages = []\n",
    "    mem_usages = []\n",
    "\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            \n",
    "            cpu_percentages.append(float(values[2][:-1]))\n",
    "            mem_usages.append(float(convert_to_mib(values[3])[:-3]))\n",
    "\n",
    "    return cpu_percentages, mem_usages\n",
    "\n",
    "\n",
    "def write_to_csv(cpu_percentages, mem_usages, output_file):\n",
    "    with open(output_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([name_mapper[\"cpu\"], name_mapper[\"memory\"]])\n",
    "        for i in range(len(cpu_percentages)):\n",
    "            writer.writerow([cpu_percentages[i], mem_usages[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_txt_files_in_folder(folder_path):\n",
    "    txt_files = []\n",
    "    try:\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".txt\") and os.path.isfile(os.path.join(folder_path, file)):\n",
    "                txt_files.append(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while listing .txt files: {e}\")\n",
    "    return txt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_20_select_all_samples__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_10_select_samples_from_1_4_to_3_4__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_10_select_samples_from_1_4_to_3_4__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_20_select_all_samples__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_20_select_all_samples__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_20_select_samples_from_1_4_to_3_4__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_20_select_all_samples__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_20_select_samples_from_1_4_to_3_4__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_20_select_all_samples__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__CPU_Usage__cpu__distributed_plugin__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_20_select_samples_from_1_4_to_3_4__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__CPU_Usage__cpu__centralized_plugin__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_20_select_samples_from_1_4_to_3_4__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_10_select_samples_from_1_4_to_3_4__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__CPU_Usage__cpu__distributed_plugin__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__CPU_Usage__cpu__centralized_plugin__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__CPU_Usage__cpu__centralized_plugin__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__CPU_Usage__cpu__distributed_plugin__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_10_select_samples_from_1_4_to_3_4__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__Memory_Usage__memory__centralized_plugin__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__Memory_Usage__memory__distributed_plugin__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__Memory_Usage__memory__distributed_plugin__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__Memory_Usage__memory__centralized_plugin__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__Memory_Usage__memory__centralized_plugin__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/janitha__Memory_Usage__memory__distributed_plugin__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_10_select_all_samples__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_10_select_all_samples__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_20_select_all_samples__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_20_select_all_samples__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_20_select_all_samples__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_10_select_all_samples__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_10_select_all_samples__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_10_select_all_samples__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_20_select_all_samples__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_20_select_all_samples__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_20_select_samples_from_1_4_to_3_4__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_10_select_samples_from_1_4_to_3_4__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_10_select_samples_from_1_4_to_3_4__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_20_select_samples_from_1_4_to_3_4__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_20_select_samples_from_1_4_to_3_4__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_10_select_samples_from_1_4_to_3_4__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_10_select_all_samples__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_10_select_all_samples__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_20_select_samples_from_1_4_to_3_4__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_10_select_all_samples__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_10_select_samples_from_1_4_to_3_4__m1.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_10_select_samples_from_1_4_to_3_4__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_20_select_samples_from_1_4_to_3_4__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_10_select_all_samples__m3.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_10_select_all_samples__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__Memory_Usage__memory__not_downsampled_overlap_to_20_select_samples_from_1_4_to_3_4__m2.csv\n",
      "Data has been written to ./2_preprocess/1_line_chart/dinil__CPU_Usage__cpu__not_downsampled_overlap_to_10_select_samples_from_1_4_to_3_4__m2.csv\n"
     ]
    }
   ],
   "source": [
    "input_folder_path = \"./1_input/\"\n",
    "preprocess_folder_path = \"./2_preprocess/\"\n",
    "line_chart_folder_path = \"1_line_chart/\"\n",
    "\n",
    "files_in_folder = list_txt_files_in_folder(input_folder_path + line_chart_folder_path)\n",
    "\n",
    "for file_name in files_in_folder:\n",
    "    input_file_path = input_folder_path + line_chart_folder_path + file_name\n",
    "    preprocess_file_path = preprocess_folder_path + line_chart_folder_path + file_name.split(\".\")[0] + \".csv\"\n",
    "\n",
    "    cpu_percentages, mem_usages = extract_info(input_file_path)\n",
    "    write_to_csv(cpu_percentages, mem_usages, preprocess_file_path)\n",
    "    \n",
    "    print(f'Data has been written to {preprocess_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_csv_files_in_folder(folder_path):\n",
    "    csv_files = []\n",
    "    try:\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".csv\") and os.path.isfile(os.path.join(folder_path, file)):\n",
    "                csv_files.append(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while listing .csv files: {e}\")\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_10_select_all_samples': ['m2', 'm3'], 'dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_10_select_samples_from_1_4_to_3_4': ['m2', 'm3'], 'dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_20_select_all_samples': ['m2', 'm3'], 'dinil__CPU_Usage__cpu__down_sampled_to_10MHz_overlap_to_20_select_samples_from_1_4_to_3_4': ['m2', 'm3'], 'dinil__CPU_Usage__cpu__not_downsampled_overlap_to_10_select_all_samples': ['m1', 'm2', 'm3'], 'dinil__CPU_Usage__cpu__not_downsampled_overlap_to_10_select_samples_from_1_4_to_3_4': ['m1', 'm2', 'm3'], 'dinil__CPU_Usage__cpu__not_downsampled_overlap_to_20_select_all_samples': ['m1', 'm2', 'm3'], 'dinil__CPU_Usage__cpu__not_downsampled_overlap_to_20_select_samples_from_1_4_to_3_4': ['m1', 'm2', 'm3'], 'dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_10_select_all_samples': ['m2', 'm3'], 'dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_10_select_samples_from_1_4_to_3_4': ['m2', 'm3'], 'dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_20_select_all_samples': ['m2', 'm3'], 'dinil__Memory_Usage__memory__down_sampled_to_10MHz_overlap_to_20_select_samples_from_1_4_to_3_4': ['m2', 'm3'], 'dinil__Memory_Usage__memory__not_downsampled_overlap_to_10_select_all_samples': ['m1', 'm2', 'm3'], 'dinil__Memory_Usage__memory__not_downsampled_overlap_to_10_select_samples_from_1_4_to_3_4': ['m1', 'm2', 'm3'], 'dinil__Memory_Usage__memory__not_downsampled_overlap_to_20_select_all_samples': ['m1', 'm2', 'm3'], 'dinil__Memory_Usage__memory__not_downsampled_overlap_to_20_select_samples_from_1_4_to_3_4': ['m1', 'm2', 'm3'], 'janitha__CPU_Usage__cpu__centralized_plugin': ['m1', 'm2', 'm3'], 'janitha__CPU_Usage__cpu__distributed_plugin': ['m1', 'm2', 'm3'], 'janitha__Memory_Usage__memory__centralized_plugin': ['m1', 'm2', 'm3'], 'janitha__Memory_Usage__memory__distributed_plugin': ['m1', 'm2', 'm3']}\n"
     ]
    }
   ],
   "source": [
    "csv_files_in_folder = list_csv_files_in_folder(preprocess_folder_path + line_chart_folder_path)\n",
    "csv_files_in_folder_sorted = sorted(csv_files_in_folder)\n",
    "\n",
    "result = {}\n",
    "\n",
    "for item in csv_files_in_folder_sorted:\n",
    "    parts = item.split(\"__\")\n",
    "    key = \"__\".join(parts[:-1])  # Join all parts except the last one\n",
    "    value = parts[-1].split(\".\")[0]\n",
    "    result.setdefault(key, []).append(value)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_folder_path = \"./3_chart/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Chart Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, values in result.items():\n",
    "    for value in values:\n",
    "        file_path = preprocess_folder_path + line_chart_folder_path + key + \"__\" + value + \".csv\"\n",
    "        usage_type = key.split(\"__\")[2]\n",
    "        title = \" \".join(key.split(\"__\")[1].split(\"_\"))\n",
    "        chart_folder = key.split(\"__\")[0]\n",
    "        usage_values = []\n",
    "        \n",
    "        with open(file_path, \"r\") as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                usage_value = float(row[name_mapper[usage_type]])\n",
    "                usage_values.append(usage_value)\n",
    "    \n",
    "        x = np.arange(len(usage_values))\n",
    "\n",
    "        y = np.array(usage_values)\n",
    "        f = interp1d(x, y, kind='cubic')\n",
    "        x_new = np.linspace(x.min(), x.max(), 300)\n",
    "        y_smooth = f(x_new)\n",
    "        \n",
    "        plt.plot(x_new, y_smooth, marker='', linestyle='-', label=name_mapper[value])\n",
    "        plt.title(title)\n",
    "        plt.xlabel(name_mapper[\"x_label\"])\n",
    "        plt.ylabel(name_mapper[usage_type])\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        chart_file_name = key + \".png\"\n",
    "        chart_file_path = chart_folder_path + chart_folder + \"/\" + line_chart_folder_path + chart_file_name\n",
    "        plt.savefig(chart_file_path, dpi=300)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box Plot Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m0 = not depends on the sandbox\n",
    "# owner__title__xlabel__ylabel__extraName__sandbox\n",
    "\n",
    "# e.g. dinil__Sampling_Rate_=_10MHz__Time_(s)__File_Size_(MB)__file_size_against_time_10MHz__m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot_folder_path = \"2_box_plot/\"\n",
    "\n",
    "csv_files_in_folder = list_csv_files_in_folder(input_folder_path + box_plot_folder_path)\n",
    "\n",
    "for filename in csv_files_in_folder:\n",
    "    data = pd.read_csv(input_folder_path + box_plot_folder_path + filename)\n",
    "    owner_name = filename.split(\"__\")[0]\n",
    "    \n",
    "\n",
    "    title = \" \".join(filename.split(\"__\")[1].split(\"_\"))\n",
    "    xlabel = \" \".join(filename.split(\"__\")[2].split(\"_\"))\n",
    "    ylabel = \" \".join(filename.split(\"__\")[3].split(\"_\"))\n",
    "\n",
    "    # Creating the box plot\n",
    "    bp = plt.boxplot(data.values, labels=data.columns, patch_artist=True)\n",
    "\n",
    "    # List of colors for each box\n",
    "    box_colors = ['pink', 'lightblue', 'lightgreen']\n",
    "\n",
    "    # Assigning colors to each box\n",
    "    for i, box in enumerate(bp['boxes']):\n",
    "        color_index = i % len(box_colors)  # Wrap around the color index\n",
    "        box.set_facecolor(box_colors[color_index])\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    # Displaying the plot\n",
    "    plt.savefig(chart_folder_path + owner_name + \"/\" + box_plot_folder_path + filename.split(\".\")[0] + \".png\", dpi=300)\n",
    "    plt.clf()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Chart Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m0 = not depends on the sandbox\n",
    "# owner__title__xlabel__ylabel__extraName__sandbox\n",
    "\n",
    "# e.g. dinil__Preproessing__Setting__File_Size_(MB)__file_size_against_preproessing_settings__m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart_folder_path = \"3_bar_chart/\"\n",
    "\n",
    "csv_files_in_folder = list_csv_files_in_folder(input_folder_path + bar_chart_folder_path)\n",
    "\n",
    "for filename in csv_files_in_folder:\n",
    "    data = pd.read_csv(input_folder_path + bar_chart_folder_path + filename)\n",
    "    owner_name = filename.split(\"__\")[0]\n",
    "    \n",
    "\n",
    "    title = \" \".join(filename.split(\"__\")[1].split(\"_\"))\n",
    "    xlabel = \" \".join(filename.split(\"__\")[2].split(\"_\"))\n",
    "    ylabel = \" \".join(filename.split(\"__\")[3].split(\"_\"))\n",
    "\n",
    "    categories = data['Category']\n",
    "    values = data['Value']\n",
    "\n",
    "    # Create bar chart\n",
    "    plt.bar(categories, values, color='skyblue')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.savefig(chart_folder_path + owner_name + \"/\" + bar_chart_folder_path + filename.split(\".\")[0] + \".png\", dpi=300)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
